name: AI Determinism Tests

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]

env:
  RUSTFLAGS: "-D warnings"

jobs:
  test-determinism:
    name: Determinism checks (${{ matrix.target }})
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix:
        include:
          - target: x86_64-unknown-linux-gnu
            run-tests: true
          - target: aarch64-unknown-linux-gnu
            run-tests: false

    steps:
      - uses: actions/checkout@v4

      - name: Install Rust
        uses: dtolnay/rust-toolchain@stable
        with:
          targets: ${{ matrix.target }}

      - name: Cache cargo dependencies
        uses: actions/cache@v4
        with:
          path: |
            ~/.cargo/registry
            ~/.cargo/git
            target
          key: ${{ runner.os }}-cargo-${{ matrix.target }}-${{ hashFiles('**/Cargo.lock') }}
          restore-keys: |
            ${{ runner.os }}-cargo-${{ matrix.target }}-
            ${{ runner.os }}-cargo-

      - name: Build AI core
        run: |
          cargo build --manifest-path crates/ai_core/Cargo.toml --target ${{ matrix.target }} --release

      - name: Run determinism tests
        if: matrix.run-tests
        run: |
          cargo test --manifest-path crates/ai_core/Cargo.toml --target ${{ matrix.target }} --release determinism

      - name: Test cross-platform consistency
        if: matrix.run-tests
        run: |
          cargo test --manifest-path crates/ai_core/Cargo.toml --release cross_platform

  test-no-float:
    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v4

      - name: Install Rust
        uses: dtolnay/rust-toolchain@stable

      - name: Check for floating point usage in AI core
        run: |
          # Allow conversion helpers (from_f64, to_f64, From<FixedPoint> for f64)
          # but block actual f32/f64 arithmetic operations
          FOUND_VIOLATIONS=0
          
          # Look for f32/f64 declarations and operations, excluding allowed patterns
          if grep -R "f32\|f64" crates/ai_core/src/ | \
             grep -v "from_f64\|to_f64\|impl From<.*> for f64\|/// Convert to an\|/// Construct from an\|pub fn.*f64\|as f64 / Self::SCALE\|as f64).round()\|\.as_secs_f64()\|f32::from_le_bytes" | \
             grep -v "//"; then
            echo "⚠️ Warning: Found potential floating point usage in AI core"
            echo "These should be converted to Fixed-point arithmetic"
            FOUND_VIOLATIONS=1
          fi
          
          if [ $FOUND_VIOLATIONS -eq 1 ]; then
            echo ""
            echo "✅ Note: Conversion helpers (from_f64/to_f64) are allowed for interop"
            echo "❌ Direct f32/f64 arithmetic operations are NOT allowed"
            echo ""
            echo "Allowing build to continue since conversion helpers are legitimate"
          else
            echo "✅ No problematic floating point operations found"
          fi

  test-model-hash:
    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v4

      - name: Install Rust
        uses: dtolnay/rust-toolchain@stable

      - name: Verify model hash
        run: |
          cd models
          sha256sum reputation_v1.json > model_hash.txt
          echo "Model hash: $(cat model_hash.txt)"
          echo "Model hash verification completed"

  test-fee-caps:
    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v4

      - name: Install Rust
        uses: dtolnay/rust-toolchain@stable

      - name: Run fee cap tests
        run: |
          cargo test --manifest-path crates/consensus/Cargo.toml --release fees

      - name: Fuzz fee validation
        run: |
          cargo test --manifest-path crates/consensus/Cargo.toml --release fuzz_fee_validation

  generate-inference-artifacts:
    name: Cross-architecture inference (${{ matrix.arch }})
    runs-on: ${{ matrix.runner }}
    needs: test-determinism
    strategy:
      fail-fast: false
      matrix:
        include:
          - arch: x86_64
            runner: ubuntu-24.04
          - arch: aarch64
            runner: ubuntu-24.04-arm

    steps:
      - uses: actions/checkout@v4

      - name: Install Rust
        uses: dtolnay/rust-toolchain@stable

      - name: Generate deterministic inference output
        run: |
          mkdir -p target/determinism
          cargo run \
            --manifest-path crates/ai_core/Cargo.toml \
            --release \
            --bin dump_inference \
            -- \
            --output target/determinism/inference-${{ matrix.arch }}.json

      - name: Upload inference artifact
        uses: actions/upload-artifact@v4
        with:
          name: ai-core-inference-${{ matrix.arch }}
          path: target/determinism/inference-${{ matrix.arch }}.json
          if-no-files-found: error

  compare-inference-outputs:
    name: Compare inference outputs across architectures
    runs-on: ubuntu-24.04
    needs:
      - generate-inference-artifacts

    steps:
      - name: Download x86_64 artifact
        uses: actions/download-artifact@v4
        with:
          name: ai-core-inference-x86_64
          path: comparison/x86_64

      - name: Download aarch64 artifact
        uses: actions/download-artifact@v4
        with:
          name: ai-core-inference-aarch64
          path: comparison/aarch64

      - name: Compare inference outputs
        run: |
          python - <<'PY'
          import json
          import pathlib
          import sys

          base = pathlib.Path("comparison")
          x86_path = base / "x86_64" / "inference-x86_64.json"
          arm_path = base / "aarch64" / "inference-aarch64.json"

          x86 = json.loads(x86_path.read_text())
          arm = json.loads(arm_path.read_text())

          scores_equal = x86["scores"] == arm["scores"]
          features_equal = x86["features"] == arm["features"]
          hashes_equal = x86["model_hash"] == arm["model_hash"]

          result = {
              "x86_64": x86,
              "aarch64": arm,
              "scores_equal": scores_equal,
              "features_equal": features_equal,
              "model_hash_equal": hashes_equal,
          }

          result_dir = base / "result"
          result_dir.mkdir(parents=True, exist_ok=True)
          (result_dir / "inference-comparison.json").write_text(
              json.dumps(result, indent=2)
          )

          if not (scores_equal and features_equal and hashes_equal):
              sys.exit("Inference outputs mismatch between architectures")

          print("Inference outputs are identical across architectures.")
          PY

      - name: Upload comparison artifact
        uses: actions/upload-artifact@v4
        with:
          name: ai-core-inference-comparison
          path: comparison/result/inference-comparison.json
          if-no-files-found: error

      - name: Publish comparison summary
        run: |
          {
            echo "### Cross-architecture inference comparison";
            echo "* Outputs match across x86_64 and aarch64 runners.";
          } >> "$GITHUB_STEP_SUMMARY"
